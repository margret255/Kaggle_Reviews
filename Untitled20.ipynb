{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOvaM6QnudOA2jisf/iL92m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/margret255/Kaggle_Reviews/blob/main/Untitled20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zsummtH1o6fl"
      },
      "outputs": [],
      "source": [
        "#importing necessary pytorch libraries and modules\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining data transformation\n",
        "transforms.ToTensor()\n",
        "transforms.Normalize((0.1307,), (0.3081,))\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        ""
      ],
      "metadata": {
        "id": "DAAc0rz-pflP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the training and test datasets\n",
        "root='./data'\n",
        "train=True\n",
        "download=True\n",
        "transform\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3V5WZu3np4tc",
        "outputId": "937c1901-be89-4d70-d529-134b35a4048c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 30.4MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 24.5MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 43.3MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 7.55MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#wrap the datasets in Dataloader objects\n",
        "shuffle=True\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)"
      ],
      "metadata": {
        "id": "1kqAOZ-PqO49"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining a simple  neural network\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "Co-cS_pmqfHH"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#instantiating the model\n",
        "model = SimpleNN()\n",
        ""
      ],
      "metadata": {
        "id": "U7ZeT6MOq2yg"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "dHS1LuArq9q3"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training loop\n",
        "for epoch in range(5):\n",
        "  model.train()\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "      optimizer.zero_grad()\n",
        "      output = model(data)\n",
        "      loss = criterion(output, target)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      if batch_idx % 100 == 0:\n",
        "            print(f\"Train Epoch: {epoch} [{batch_idx * len(data)} /{len(train_loader.dataset)}] Loss: {loss.item()}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "72L998eWrCDN"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluation loop\n",
        "model.eval()\n",
        "test_loss = 0\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "            output = model(data)                # Compute output for test data.\n",
        "            test_loss += criterion(output, target).item()  # Sum up batch losses.\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # Get the index of the max logit (predicted class).\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()  # Count correct predictions."
      ],
      "metadata": {
        "id": "MUeACcHCrpYC"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss /= len(test_loader.dataset)  # Compute average loss.\n",
        "accuracy = 100. * correct / len(test_loader.dataset)  # Calculate accuracy in percentage.\n",
        "print(f\"\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({accuracy:.2f}%)\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdJgSyNEr71d",
        "outputId": "486a9e2e-37cd-43ab-9f4b-bb0e11d4700a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0001, Accuracy: 9773/10000 (97.73%)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}